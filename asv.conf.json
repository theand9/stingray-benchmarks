{
    // The version of the config file format.  Do not change, unless
    // you know what you are doing.
    "version": 1,
    // The name of the project being benchmarked
    "project": "StingraySoftware/stingray",
    // The project's homepage
    "project_url": "https://stingray.readthedocs.io/",
    // Comment the first line and uncomment and edit the second if you are testing local changes.
    "repo": "https://github.com/StingraySoftware/stingray.git",
    // "repo": "/path/to/your/local/repo",
    // List of branches to benchmark.
    "branches": [
        "master"
    ],
    // The DVCS being used.
    "dvcs": "git",
    // The tool to use to create environments.  May be "conda",
    // "virtualenv" or other value depending on the plugins in use.
    // If missing or the empty string, the tool will be automatically
    // determined by looking for tools on the PATH environment
    // variable./
    "environment_type": "env", // conda in astropy and "virtualenv" in numpy, scipy
    // "environment_type": "virtualenv",
    // the base URL to show a commit for the project.
    "show_commit_url": "https://github.com/StingraySoftware/stingray/commits",
    // The Pythons you'd like to test against.  If not provided, defaults
    // to the current version of Python used to run `asv`.
    "pythons": [
        "3.6"
    ],
    // The matrix of dependencies to test.  Each key is the name of a
    // package (in PyPI) and the values are version numbers.  An empty
    // list or empty string indicates to just test against the default
    // (latest) version. null indicates that the package is to not be
    // installed. If the package to be tested is only available from
    // PyPi, and the 'environment_type' is conda, then you can preface
    // the package name by 'pip+', and the package will be installed via
    // pip (with all the conda available packages installed first,
    // followed by the pip installed packages).
    //
    "matrix": {
        "numpy": [],
        "scipy": [],
        "matplotlib": [],
        "astropy": [],
        "numba": []
    },
    // The directory (relative to the current directory) that benchmarks are
    // stored in.  defaults to "benchmarks"
    "benchmark_dir": "benchmarks",
    // The directory (relative to the current directory) to cache the Python
    // environments in.  If not provided, defaults to "env"
    "env_dir": "env",
    // The directory (relative to the current directory) that raw benchmark
    // results are stored in.  If not provided, defaults to "results".
    "results_dir": "results",
    // The directory (relative to the current directory) that the html tree
    // should be written to.  If not provided, defaults to "html".
    "html_dir": "html",
    // The number of characters to retain in the commit hashes.
    "hash_length": 8,
    // `asv` will cache results of the recent builds in each
    // environment, making them faster to install next time.  This is
    // the number of builds to keep, per environment.
    // "build_cache_size": 2,
    // The commits after which the regression search in `asv publish`
    // should start looking for regressions. Dictionary whose keys are
    // regexps matching to benchmark names, and values corresponding to
    // the commit (exclusive) after which to start looking for
    // regressions.  The default is to start from the first commit
    // with results. If the commit is `null`, regression detection is
    // skipped for the matching benchmark.
    //
    // "regressions_first_commits": {
    //    "some_benchmark": "352cdf",  // Consider regressions only after this commit
    //    "another_benchmark": null,   // Skip regression detection altogether
    // },
}
